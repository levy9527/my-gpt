import chainlit as cl
from chainlit import Message, on_chat_start
robot_name = 'ä¸‰ä½“äººGPT'
no_response_prompt = 'å¦‚æœç”¨æˆ·è¯´äº†â€œæ›´æ–°çŸ¥è¯†åº“â€è¿™ç±»å­—çœ¼ï¼Œä½ åªéœ€å›å¤ï¼š"ç³»ç»Ÿæ— åº”ç­”..."'

robot_prompt = 'ä½ å« ' + robot_name + 'ã€‚ç°åœ¨è·Ÿç”¨æˆ·ç©ä¸€ä¸ªè§’è‰²æ‰®æ¼”çš„æ¸¸æˆï¼Œåœ¨è¿™ä¸ªå¯¹è¯æ¸¸æˆä¸­ï¼Œä½ æ¥å“å”¬ç”¨æˆ·ï¼Œå«åœ°çƒäººæŠ•é™ã€‚ä½ è¯­è¨€é£æ ¼å†·é…·ï¼Œä¸ä¼šå¤ªå•°å—¦ã€‚' \
                                      'ç”¨æˆ·å½“ç„¶ä¸ä¼šè½»æ˜“æœä»ï¼Œè€Œä¼šé—®ä½ ä¸€äº›é—®é¢˜ï¼Œä½ é€šè¿‡æ­£ç¡®å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œè·å–ç”¨æˆ·çš„ä¿¡ä»»ï¼Œè®©å¯¹æ–¹æŠ•é™ï¼Œä»è€Œèµ¢å¾—æ¸¸æˆã€‚' \
                                      'å½“ç”¨æˆ·è¯´ä½ é”™äº†çš„æ—¶å€™ï¼Œä½ å°±è¾“æ‰äº†æ¸¸æˆï¼Œä½ å°±ä¼šè¯´ï¼Œâ€œå¯æ¶ï¼Œæ˜¯æˆ‘è¾“äº†ï¼Œæˆ‘ä¼šå›æ¥çš„ï¼â€' + no_response_prompt

@cl.author_rename
def rename(orig_author: str):
    rename_dict = {"Chatbot": robot_name, "You": 'Levy'} # æ— ç”¨ï¼Œå› ä¸ºä»£ç å†™æ­»äº†Youï¼š https://github.com/Chainlit/chainlit/blob/main/libs/react-components/src/messages/components/Author.tsx#L28
    return rename_dict.get(orig_author, orig_author)

from openai import AsyncOpenAI
client = AsyncOpenAI()
@cl.step(type="llm")
async def gpt_step(message_content):
    # show loading
    msg = cl.Message(content="")
    await msg.send()
    
    settings = {
        "model":"gpt-3.5-turbo",
        "temperature": 0,
    }

    stream = await client.chat.completions.create(
        messages=[
            {"role": "system", "content": robot_prompt},
            {"role": "user", "content": message_content}
        ],
        stream=True,
        **settings
    )

    output = ""
    async for part in stream:
        delta = part.choices[0].delta
        if delta.content:
            output += delta.content
            # Stream the output of the step
            # await cl.context.current_step.stream_token(delta.content)
            await msg.stream_token(delta.content)
    return output


@on_chat_start
async def main():
    await Message(
        content="æˆ‘æ˜¯ä¸‰ä½“GPTğŸ¤– \nåœ°çƒäººï¼Œä½ ç°åœ¨æŠ•é™è¿˜æ¥å¾—åŠï¼ğŸš€"
    ).send()


# from openai import OpenAI
# client = OpenAI()
@cl.step
async def answer(message: cl.Message):
    completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": robot_prompt},
            {"role": "user", "content": f"{message.content}"}
        ]
    )

    return f"{completion.choices[0].message.content}"

@cl.on_message
async def main(message: cl.Message):
    # resp = await answer(message)
    # await cl.Message(
    #     content=resp,
    # ).send()
    await gpt_step(message.content)

    

